{
  "model": "/data/data/com.termux/files/home/models/Llama-3.2-3B-Instruct-Q4_0.gguf",
  "model_slug": "Llama-3.2-3B-Instruct-Q4_0.gguf",
  "question_count": 10,
  "retrieval_latency_ms": {
    "avg": 2.830093500051589,
    "min": 0.8042710005611298,
    "max": 3.7907810001343023
  },
  "semantic_similarity_avg": 0.4282799570226887,
  "session_carbon_emissions_kg": 4.052542197461194e-06,
  "evaluation": {
    "exact_match": 0.0,
    "f1": 0.5268923507009157,
    "question_count": 10
  },
  "artifacts": {
    "raw_outputs": "/root/llama3.2-3b-ragres1/Llama-3.2-3B-Instruct-Q4_0.gguf/raw_outputs_Llama-3.2-3B-Instruct-Q4_0.gguf.json",
    "parsed_outputs": "/root/llama3.2-3b-ragres1/Llama-3.2-3B-Instruct-Q4_0.gguf/parsed_outputs_Llama-3.2-3B-Instruct-Q4_0.gguf.json",
    "raw_metrics": "/root/llama3.2-3b-ragres1/Llama-3.2-3B-Instruct-Q4_0.gguf/raw_metrics.json",
    "evaluation_metrics": "/root/llama3.2-3b-ragres1/Llama-3.2-3B-Instruct-Q4_0.gguf/evaluation_metrics.json",
    "summary_metrics": "/root/llama3.2-3b-ragres1/Llama-3.2-3B-Instruct-Q4_0.gguf/summary_metrics.json",
    "prompt_log": "/root/llama3.2-3b-ragres1/Llama-3.2-3B-Instruct-Q4_0.gguf/prompt_log.json"
  }
}